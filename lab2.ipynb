{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Maximum Matching (FMM): ['i', 'love', 'program', 'ming', 'language']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "nltk.download('words')\n",
    "\n",
    "word_list = set(word.lower() for word in words.words())\n",
    "\n",
    "max_word_length = max(len(word) for word in word_list)\n",
    "\n",
    "def forward_maximum_matching(text):\n",
    "    result = []\n",
    "    index = 0\n",
    "    text = text.lower()  \n",
    "    text_length = len(text)\n",
    "\n",
    "    while index < text_length:\n",
    "        match = None\n",
    "        for size in range(max_word_length, 0, -1):\n",
    "            end_index = index + size\n",
    "            if end_index > text_length:\n",
    "                continue\n",
    "            piece = text[index:end_index]\n",
    "            if piece in word_list:\n",
    "                match = piece\n",
    "                break\n",
    "\n",
    "        if match:\n",
    "            result.append(match)\n",
    "            index += len(match)\n",
    "        else:\n",
    "            result.append(text[index])\n",
    "            index += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "input_text = \"iloveprogramminglanguage\"\n",
    "\n",
    "fmm_result = forward_maximum_matching(input_text)\n",
    "\n",
    "print(\"Forward Maximum Matching (FMM):\", fmm_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Maximum Matching (FMM): ['i', 'love', 'programming', 'language']\n",
      "Backward Maximum Matching (BMM): ['i', 'love', 'programming', 'language']\n"
     ]
    }
   ],
   "source": [
    "# Sample dictionary of words\n",
    "dictionary = {\"i\", \"love\", \"program\", \"programming\", \"pro\", \"gram\", \"ming\", \"language\", \"python\", \"java\"}\n",
    "\n",
    "# Find the maximum length of any word in the dictionary\n",
    "max_word_length = max(len(word) for word in dictionary)\n",
    "\n",
    "def forward_maximum_matching(text):\n",
    "    result = []\n",
    "    index = 0\n",
    "    text_length = len(text)\n",
    "\n",
    "    while index < text_length:\n",
    "        # Start by taking the maximum possible length\n",
    "        match = None\n",
    "        # From longest possible word to 1 character\n",
    "        for size in range(max_word_length, 0, -1):\n",
    "            end_index = index + size\n",
    "            # Avoid going out of bounds\n",
    "            if end_index > text_length:\n",
    "                continue\n",
    "            piece = text[index:end_index]\n",
    "            if piece in dictionary:\n",
    "                match = piece\n",
    "                break\n",
    "\n",
    "        if match:\n",
    "            result.append(match)\n",
    "            index += len(match)\n",
    "        else:\n",
    "            # No match found, take one character as a token (unknown word)\n",
    "            result.append(text[index])\n",
    "            index += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "def backward_maximum_matching(text):\n",
    "    result = []\n",
    "    index = len(text)\n",
    "\n",
    "    while index > 0:\n",
    "        match = None\n",
    "        # From longest possible word to 1 character\n",
    "        for size in range(max_word_length, 0, -1):\n",
    "            start_index = index - size\n",
    "            if start_index < 0:\n",
    "                continue\n",
    "            piece = text[start_index:index]\n",
    "            if piece in dictionary:\n",
    "                match = piece\n",
    "                break\n",
    "\n",
    "        if match:\n",
    "            result.insert(0, match)\n",
    "            index -= len(match)\n",
    "        else:\n",
    "            # No match found, take one character as a token (unknown word)\n",
    "            result.insert(0, text[index - 1])\n",
    "            index -= 1\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "input_text = \"iloveprogramminglanguage\"\n",
    "\n",
    "fmm_result = forward_maximum_matching(input_text)\n",
    "bmm_result = backward_maximum_matching(input_text)\n",
    "\n",
    "print(\"Forward Maximum Matching (FMM):\", fmm_result)\n",
    "print(\"Backward Maximum Matching (BMM):\", bmm_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Vocabulary: {'p', 's', 'm', 't', 'a', 'in', 'g', 'n', 'happin', 'h', 'y', 'happ', 'e', 'o', 'r'}\n",
      "Merges Applied: [('h', 'a'), ('ha', 'p'), ('hap', 'p'), ('i', 'n'), ('happ', 'in')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def get_pairs(word_list):\n",
    "    \"\"\"Extracts pairs of adjacent characters from words\"\"\"\n",
    "    pairs = Counter()\n",
    "    for word in word_list:\n",
    "        for i in range(len(word)-1):\n",
    "            pairs[(word[i], word[i+1])] += 1\n",
    "    return pairs\n",
    "\n",
    "def merge_most_frequent(pairs, word_list):\n",
    "    \"\"\"Finds and merges the most frequent pair in the word list\"\"\"\n",
    "    if not pairs:\n",
    "        return word_list, None\n",
    "\n",
    "    most_common_pair = max(pairs, key=pairs.get)  \n",
    "    new_word_list = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        new_word = []\n",
    "        i = 0\n",
    "        while i < len(word):\n",
    "            if i < len(word) - 1 and (word[i], word[i+1]) == most_common_pair:\n",
    "                new_word.append(word[i] + word[i+1])  \n",
    "                i += 2  \n",
    "            else:\n",
    "                new_word.append(word[i])\n",
    "                i += 1\n",
    "        new_word_list.append(new_word)\n",
    "    \n",
    "    return new_word_list, most_common_pair\n",
    "\n",
    "def byte_pair_encoding(corpus, num_merges=10):\n",
    "    \"\"\"Applies BPE tokenization to a given corpus\"\"\"\n",
    "\n",
    "    word_list = [list(word) for word in corpus.split()]\n",
    "    \n",
    "    \n",
    "    merges = []\n",
    "    for _ in range(num_merges):\n",
    "        pairs = get_pairs(word_list)\n",
    "        word_list, merge = merge_most_frequent(pairs, word_list)\n",
    "        if merge:\n",
    "            merges.append(merge)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    vocab = set(token for word in word_list for token in word)\n",
    "\n",
    "    return vocab, merges\n",
    "\n",
    "corpus = \"happiness happy python programming\"\n",
    "vocab, merges = byte_pair_encoding(corpus, num_merges=5)\n",
    "\n",
    "print(\"Final Vocabulary:\", vocab)\n",
    "print(\"Merges Applied:\", merges)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
